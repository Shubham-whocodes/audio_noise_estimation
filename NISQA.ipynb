{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: datasets in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (3.2.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (3.11.10)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (0.26.5)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging->datasets) (3.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers==4.19.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (4.19.2)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.19.2) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.19.2) (0.26.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.19.2) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.19.2) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.19.2) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.19.2) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.19.2) (2.32.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.19.2) (0.12.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.19.2) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.19.2) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.19.2) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.19.2) (3.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.19.2) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.19.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.19.2) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.19.2) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: jiwer in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (3.0.5)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jiwer) (8.1.7)\n",
      "Requirement already satisfied: rapidfuzz<4,>=3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jiwer) (3.10.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchaudio in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torchaudio) (2.2.2)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch->torchaudio) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch->torchaudio) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch->torchaudio) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch->torchaudio) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch->torchaudio) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch->torchaudio) (2024.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch->torchaudio) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch->torchaudio) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: librosa in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.10.2.post1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from librosa) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from librosa) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from librosa) (1.5.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from librosa) (4.12.2)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from lazy-loader>=0.1->librosa) (21.3)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pooch>=1.1->librosa) (4.3.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging->lazy-loader>=0.1->librosa) (3.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: accelerate in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.2.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (21.3)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (2.2.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (0.26.5)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.9.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.2.0)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: wandb in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.19.0)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from wandb) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from wandb) (4.25.5)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from wandb) (6.0.0)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from wandb) (2.9.2)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from wandb) (2.19.2)\n",
      "Requirement already satisfied: setproctitle in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from wandb) (1.3.4)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from wandb) (75.2.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from wandb) (4.12.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3,>=2.6->wandb) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "%pip install torch\n",
    "%pip install datasets\n",
    "%pip install transformers==4.19.2\n",
    "%pip install jiwer\n",
    "%pip install torchaudio\n",
    "%pip install librosa\n",
    "%pip install accelerate -U\n",
    "\n",
    "# Monitor the training process\n",
    "%pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: LC_ALL=C.UTF-8\n",
      "env: LANG=C.UTF-8\n",
      "env: TRANSFORMERS_CACHE=/home/ec2-user/SageMaker/cache\n",
      "env: HF_DATASETS_CACHE=/home/ec2-user/SageMaker/cache\n",
      "env: CUDA_LAUNCH_BLOCKING=1\n"
     ]
    }
   ],
   "source": [
    "%env LC_ALL=C.UTF-8\n",
    "%env LANG=C.UTF-8\n",
    "%env TRANSFORMERS_CACHE=/home/ec2-user/SageMaker/cache\n",
    "%env HF_DATASETS_CACHE=/home/ec2-user/SageMaker/cache\n",
    "%env CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from glob import glob\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd; pd.options.mode.chained_assignment=None\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import wandb\n",
    "from torch.utils.data import DataLoader\n",
    "import NISQA_lib as NL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class nisqaModel(object):    \n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        \n",
    "        if 'mode' not in self.args:\n",
    "            self.args['mode'] = 'main'\n",
    "            \n",
    "        self.runinfos = {}       \n",
    "        self._getDevice()\n",
    "        self._loadModel()\n",
    "        self._loadDatasets()\n",
    "        self.args['now'] = datetime.datetime.today()\n",
    "        \n",
    "        \n",
    "        if self.args['mode']=='main':\n",
    "            print(yaml.dump(self.args, default_flow_style=None, sort_keys=False))  \n",
    "            \n",
    "    def evaluate(self, mapping='first_order', do_print=True, do_plot=False):\n",
    "        if self.args['dim']==True:\n",
    "            self._evaluate_dim(mapping=mapping, do_print=do_print, do_plot=do_plot)\n",
    "        else:\n",
    "            self._evaluate_mos(mapping=mapping, do_print=do_print, do_plot=do_plot)      \n",
    "            \n",
    "    def predict(self):\n",
    "        print('---> Predicting ...')\n",
    "        if self.args['tr_parallel']:\n",
    "            self.model = nn.DataParallel(self.model)           \n",
    "        \n",
    "        if self.args['dim']==True:\n",
    "            y_val_hat, y_val = NL.predict_dim(\n",
    "                self.model, \n",
    "                self.ds_val, \n",
    "                self.args['tr_bs_val'],\n",
    "                self.dev,\n",
    "                num_workers=self.args['tr_num_workers'])\n",
    "        else:\n",
    "            y_val_hat, y_val = NL.predict_mos(\n",
    "                self.model, \n",
    "                self.ds_val, \n",
    "                self.args['tr_bs_val'],\n",
    "                self.dev,\n",
    "                num_workers=self.args['tr_num_workers'])                 \n",
    "                    \n",
    "        if self.args['output_dir']:\n",
    "            self.ds_val.df['model'] = self.args['name']\n",
    "            self.ds_val.df.to_csv(\n",
    "                os.path.join(self.args['output_dir'], 'NISQA_results.csv'), \n",
    "                index=False)\n",
    "            \n",
    "        return self.ds_val.df\n",
    "\n",
    "    def _train_mos(self):\n",
    "        '''\n",
    "        Trains speech quality model.\n",
    "        '''\n",
    "        # Initialize  -------------------------------------------------------------\n",
    "        if self.args['tr_parallel']:\n",
    "            self.model = nn.DataParallel(self.model)\n",
    "        self.model.to(self.dev)\n",
    "\n",
    "        # Runname and savepath  ---------------------------------------------------\n",
    "        self.runname = self._makeRunnameAndWriteYAML()\n",
    "\n",
    "        # Optimizer  -------------------------------------------------------------\n",
    "        opt = optim.Adam(self.model.parameters(), lr=self.args['tr_lr'])        \n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                opt,\n",
    "                'min',\n",
    "                verbose=True,\n",
    "                threshold=0.003,\n",
    "                patience=self.args['tr_lr_patience'])\n",
    "        earlyStp = NL.earlyStopper(self.args['tr_early_stop'])      \n",
    "        \n",
    "        biasLoss = NL.biasLoss(\n",
    "            self.ds_train.df.filepath, \n",
    "            anchor_db=self.args['tr_bias_anchor_db'], \n",
    "            mapping=self.args['tr_bias_mapping'], \n",
    "            min_r=self.args['tr_bias_min_r'],\n",
    "            do_print=(self.args['tr_verbose']>0),\n",
    "            )\n",
    "\n",
    "        # Dataloader    -----------------------------------------------------------\n",
    "        dl_train = DataLoader(\n",
    "            self.ds_train,\n",
    "            batch_size=self.args['tr_bs'],\n",
    "            shuffle=True,\n",
    "            drop_last=False,\n",
    "            pin_memory=True,\n",
    "            num_workers=self.args['tr_num_workers'])\n",
    "        \n",
    "        # Start training loop   ---------------------------------------------------\n",
    "        print('--> start training')\n",
    "        \n",
    "        for epoch in range(self.args['tr_epochs']):\n",
    "            tic_epoch = time.time()\n",
    "            batch_cnt = 0\n",
    "            loss = 0.0\n",
    "            y_train = self.ds_train.df[self.args['csv_mos_train']].to_numpy().reshape(-1)\n",
    "            y_train_hat = np.zeros((len(self.ds_train), 1))\n",
    "            self.model.train()\n",
    "            \n",
    "            # Progress bar\n",
    "            if self.args['tr_verbose'] == 2:\n",
    "                pbar = tqdm(iterable=batch_cnt, total=len(dl_train), ascii=\">â€”\",\n",
    "                            bar_format='{bar} {percentage:3.0f}%, {n_fmt}/{total_fmt}, {elapsed}<{remaining}{postfix}')\n",
    "                \n",
    "            for xb_spec, yb_mos, (idx, n_wins) in dl_train:\n",
    "\n",
    "                # Estimate batch ---------------------------------------------------\n",
    "                xb_spec = xb_spec.to(self.dev)\n",
    "                yb_mos = yb_mos.to(self.dev)\n",
    "                n_wins = n_wins.to(self.dev)\n",
    "\n",
    "                # Forward pass ----------------------------------------------------\n",
    "                yb_mos_hat = self.model(xb_spec, n_wins)\n",
    "                y_train_hat[idx] = yb_mos_hat.detach().cpu().numpy()\n",
    "\n",
    "                # Loss ------------------------------------------------------------       \n",
    "                lossb = biasLoss.get_loss(yb_mos, yb_mos_hat, idx)\n",
    "                # Backprop  -------------------------------------------------------\n",
    "                lossb.backward()\n",
    "                opt.step()\n",
    "                opt.zero_grad()\n",
    "\n",
    "                # Update total loss -----------------------------------------------\n",
    "                loss += lossb.item()\n",
    "                batch_cnt += 1\n",
    "\n",
    "                if self.args['tr_verbose'] == 2:\n",
    "                    pbar.set_postfix(loss=lossb.item())\n",
    "                    pbar.update()\n",
    "\n",
    "            if self.args['tr_verbose'] == 2:\n",
    "                pbar.close()\n",
    "\n",
    "            loss = loss/batch_cnt\n",
    "            \n",
    "            biasLoss.update_bias(y_train, y_train_hat)\n",
    "            \n",
    "\n",
    "            # Evaluate   -----------------------------------------------------------\n",
    "            if self.args['tr_verbose']>0:\n",
    "                print('\\n<---- Training ---->')\n",
    "            self.ds_train.df['mos_pred'] = y_train_hat\n",
    "            db_results_train, r_train = NL.eval_results(\n",
    "                self.ds_train.df, \n",
    "                dcon=self.ds_train.df_con, \n",
    "                target_mos=self.args['csv_mos_train'],\n",
    "                target_ci=self.args['csv_mos_train'] + '_ci',\n",
    "                pred='mos_pred',\n",
    "                mapping = 'first_order',\n",
    "                do_print=(self.args['tr_verbose']>0)\n",
    "                )\n",
    "            \n",
    "            \n",
    "            if self.args['tr_verbose']>0:\n",
    "                print('<---- Validation ---->')\n",
    "            NL.predict_mos(self.model, self.ds_val, self.args['tr_bs_val'], self.dev, num_workers=self.args['tr_num_workers'])\n",
    "            NL.predict_mos(self.model, self.ds_test, self.args['tr_bs_val'], self.dev, num_workers=self.args['tr_num_workers'])\n",
    "\n",
    "            db_results, r_val = NL.eval_results(\n",
    "                self.ds_val.df, \n",
    "                dcon=self.ds_val.df_con, \n",
    "                target_mos=self.args['csv_mos_val'],\n",
    "                target_ci=self.args['csv_mos_val'] + '_ci',\n",
    "                pred='mos_pred',\n",
    "                mapping = 'first_order',\n",
    "                do_print=(self.args['tr_verbose']>0)\n",
    "                )    \n",
    "            db_results, r_test = NL.eval_results(\n",
    "                self.ds_test.df, \n",
    "                dcon=self.ds_test.df_con, \n",
    "                target_mos=self.args['csv_mos_test'],\n",
    "                target_ci=self.args['csv_mos_test'] + '_ci',\n",
    "                pred='mos_pred',\n",
    "                mapping = 'first_order',\n",
    "                do_print=(self.args['tr_verbose']>0)\n",
    "                )   \n",
    "            \n",
    "            \n",
    "            r = {\n",
    "                 'train_pearson': r_train['r_p_all'],\n",
    "                 'train_spearman': r_train['r_s_all'],\n",
    "                 'train_mse': r_train['rmse_all'],\n",
    "                 \n",
    "                 'val_pearson': r_val['r_p_all'],\n",
    "                 'val_spearman': r_val['r_s_all'],\n",
    "                 'val_mse': r_val['rmse_all'],\n",
    "                 \n",
    "                 'test_pearson': r_test['r_p_all'],\n",
    "                 'test_spearman': r_test['r_s_all'],\n",
    "                 'test_mse': r_test['rmse_all']\n",
    "                }\n",
    "            \n",
    "            # Scheduler update    ---------------------------------------------\n",
    "            scheduler.step(loss)\n",
    "            # earl_stp = earlyStp.step(r)   \n",
    "              \n",
    "            wandb.log(r)       \n",
    "\n",
    "            # Print    --------------------------------------------------------\n",
    "            ep_runtime = time.time() - tic_epoch\n",
    "          \n",
    "            self._saveResults(self.model, self.model_args, opt, epoch, loss, ep_runtime, r, db_results, earlyStp.best)\n",
    "\n",
    "            # # Early stopping    -----------------------------------------------\n",
    "            # if earl_stp:\n",
    "            #     print('--> Early stopping. best_r_p {:0.2f} best_rmse {:0.2f}'\n",
    "            #         .format(earlyStp.best_r_p, earlyStp.best_rmse))\n",
    "            #     return        \n",
    "\n",
    "#         print('--> Training done. best_r_p {:0.2f} best_rmse_map {:0.2f}'\n",
    "#                             .format(earlyStp.best_r_p, earlyStp.best_rmse))        \n",
    "        return        \n",
    "     \n",
    "        \n",
    "    \n",
    "    def _evaluate_mos(self, mapping='first_order', do_print=True, do_plot=False):\n",
    "        '''\n",
    "        Evaluates the model's predictions.\n",
    "        '''        \n",
    "        print('--> MOS:')\n",
    "        self.db_results, self.r = NL.eval_results(\n",
    "            self.ds_val.df,\n",
    "            dcon=self.ds_val.df_con,\n",
    "            target_mos='mos',\n",
    "            target_ci='mos_ci',\n",
    "            pred='mos_pred',\n",
    "            mapping=mapping,\n",
    "            do_print=do_print,\n",
    "            do_plot=do_plot\n",
    "            )\n",
    "\n",
    "    def _makeRunnameAndWriteYAML(self):\n",
    "        runname = self.args['name']\n",
    "        print('runname: ' + runname)\n",
    "        yaml_path = os.path.join(self.args['output_dir'], runname+'.yaml')\n",
    "        Path(self.args['output_dir']).mkdir(parents=True, exist_ok=True)\n",
    "        with open(yaml_path, 'w') as file:\n",
    "            yaml.dump(self.args, file, default_flow_style=None, sort_keys=False)\n",
    "        return runname\n",
    "    \n",
    "    def _loadDatasets(self):\n",
    "        if self.args['mode']=='predict_file':\n",
    "            self._loadDatasetsFile()\n",
    "        elif self.args['mode']=='predict_dir':\n",
    "            self._loadDatasetsFolder()  \n",
    "        elif self.args['mode']=='predict_csv':\n",
    "            self._loadDatasetsCSVpredict()\n",
    "        elif self.args['mode']=='main':\n",
    "            self._loadDatasetsCSV()\n",
    "        else:\n",
    "            raise NotImplementedError('mode not available')                        \n",
    "            \n",
    "    \n",
    "    def _loadDatasetsFolder(self):\n",
    "        files = glob( os.path.join(self.args['data_dir'], '*.wav') )\n",
    "        files = [os.path.basename(files) for files in files]\n",
    "        df_val = pd.DataFrame(files, columns=['deg'])\n",
    "     \n",
    "        print('# files: {}'.format( len(df_val) ))\n",
    "        if len(df_val)==0:\n",
    "            raise ValueError('No wav files found in data_dir')   \n",
    "        \n",
    "        # creating Datasets ---------------------------------------------------                        \n",
    "        self.ds_val = NL.SpeechQualityDataset(\n",
    "            df_val,\n",
    "            df_con=None,\n",
    "            data_dir = self.args['data_dir'],\n",
    "            filename_column = 'deg',\n",
    "            mos_column = 'predict_only',              \n",
    "            seg_length = self.args['ms_seg_length'],\n",
    "            max_length = self.args['ms_max_segments'],\n",
    "            to_memory = None,\n",
    "            to_memory_workers = None,\n",
    "            seg_hop_length = self.args['ms_seg_hop_length'],\n",
    "            transform = None,\n",
    "            ms_n_fft = self.args['ms_n_fft'],\n",
    "            ms_hop_length = self.args['ms_hop_length'],\n",
    "            ms_win_length = self.args['ms_win_length'],\n",
    "            ms_n_mels = self.args['ms_n_mels'],\n",
    "            ms_sr = self.args['ms_sr'],\n",
    "            ms_fmax = self.args['ms_fmax'],\n",
    "            ms_channel = self.args['ms_channel'],\n",
    "            double_ended = self.args['double_ended'],\n",
    "            dim = self.args['dim'],\n",
    "            filename_column_ref = None,\n",
    "            )\n",
    "        \n",
    "        \n",
    "    def _loadDatasetsFile(self):\n",
    "        data_dir = os.path.dirname(self.args['deg'])\n",
    "        file_name = os.path.basename(self.args['deg'])        \n",
    "        df_val = pd.DataFrame([file_name], columns=['deg'])\n",
    "                \n",
    "        # creating Datasets ---------------------------------------------------                        \n",
    "        self.ds_val = NL.SpeechQualityDataset(\n",
    "            df_val,\n",
    "            df_con=None,\n",
    "            data_dir = data_dir,\n",
    "            filename_column = 'deg',\n",
    "            mos_column = 'predict_only',              \n",
    "            seg_length = self.args['ms_seg_length'],\n",
    "            max_length = self.args['ms_max_segments'],\n",
    "            to_memory = None,\n",
    "            to_memory_workers = None,\n",
    "            seg_hop_length = self.args['ms_seg_hop_length'],\n",
    "            transform = None,\n",
    "            ms_n_fft = self.args['ms_n_fft'],\n",
    "            ms_hop_length = self.args['ms_hop_length'],\n",
    "            ms_win_length = self.args['ms_win_length'],\n",
    "            ms_n_mels = self.args['ms_n_mels'],\n",
    "            ms_sr = self.args['ms_sr'],\n",
    "            ms_fmax = self.args['ms_fmax'],\n",
    "            ms_channel = self.args['ms_channel'],\n",
    "            double_ended = self.args['double_ended'],\n",
    "            dim = self.args['dim'],\n",
    "            filename_column_ref = None,\n",
    "        )\n",
    "                \n",
    "        \n",
    "    def _loadDatasetsCSVpredict(self):         \n",
    "        '''\n",
    "        Loads validation dataset for prediction only.\n",
    "        '''            \n",
    "        csv_file_path = os.path.join(self.args['data_dir'], self.args['csv_file'])\n",
    "        dfile = pd.read_csv(csv_file_path)\n",
    "        if 'csv_con' in self.args:\n",
    "            csv_con_file_path = os.path.join(self.args['data_dir'], self.args['csv_con'])\n",
    "            dcon = pd.read_csv(csv_con_file_path)        \n",
    "        else:\n",
    "            dcon = None\n",
    "        \n",
    "\n",
    "        # creating Datasets ---------------------------------------------------                        \n",
    "        self.ds_val = NL.SpeechQualityDataset(\n",
    "            dfile,\n",
    "            df_con=dcon,\n",
    "            data_dir = self.args['data_dir'],\n",
    "            filename_column = self.args['csv_deg'],\n",
    "            mos_column = 'predict_only',              \n",
    "            seg_length = self.args['ms_seg_length'],\n",
    "            max_length = self.args['ms_max_segments'],\n",
    "            to_memory = False,\n",
    "            to_memory_workers = None,\n",
    "            seg_hop_length = self.args['ms_seg_hop_length'],\n",
    "            transform = None,\n",
    "            ms_n_fft = self.args['ms_n_fft'],\n",
    "            ms_hop_length = self.args['ms_hop_length'],\n",
    "            ms_win_length = self.args['ms_win_length'],\n",
    "            ms_n_mels = self.args['ms_n_mels'],\n",
    "            ms_sr = self.args['ms_sr'],\n",
    "            ms_fmax = self.args['ms_fmax'],\n",
    "            ms_channel = self.args['ms_channel'],\n",
    "            double_ended = self.args['double_ended'],\n",
    "            dim = self.args['dim'],\n",
    "            filename_column_ref = self.args['csv_ref'],\n",
    "        )\n",
    "\n",
    "        \n",
    "    def _loadDatasetsCSV(self):    \n",
    "        dfile_train = pd.read_csv(self.args['csv_file'])\n",
    "        dfile_val = pd.read_csv(self.args['csv_file_val'])\n",
    "        dfile_test = pd.read_csv(self.args['csv_file_test'])\n",
    "        \n",
    "        df_train = dfile_train.reset_index()\n",
    "        df_val = dfile_val.reset_index()\n",
    "        df_test = dfile_test.reset_index()\n",
    "        \n",
    "        if self.args['csv_con'] is not None:\n",
    "            dcon = None        \n",
    "            dcon_train = None        \n",
    "            dcon_val = None        \n",
    "        else:\n",
    "            dcon = None        \n",
    "            dcon_train = None        \n",
    "            dcon_val = None        \n",
    "        \n",
    "        print('Training size: {}, Validation size: {}'.format(len(df_train), len(df_val)))\n",
    "        \n",
    "        # creating Datasets ---------------------------------------------------                        \n",
    "        self.ds_train = NL.SpeechQualityDataset(\n",
    "            df_train,\n",
    "            df_con=dcon_train,\n",
    "            data_dir = self.args['data_dir'] + '/' + self.args['csv_db_train'][0],\n",
    "            filename_column = self.args['csv_deg'],\n",
    "            mos_column = self.args['csv_mos_train'],            \n",
    "            seg_length = self.args['ms_seg_length'],\n",
    "            max_length = self.args['ms_max_segments'],\n",
    "            to_memory = self.args['tr_ds_to_memory'],\n",
    "            to_memory_workers = self.args['tr_ds_to_memory_workers'],\n",
    "            seg_hop_length = self.args['ms_seg_hop_length'],\n",
    "            transform = None,\n",
    "            ms_n_fft = self.args['ms_n_fft'],\n",
    "            ms_hop_length = self.args['ms_hop_length'],\n",
    "            ms_win_length = self.args['ms_win_length'],\n",
    "            ms_n_mels = self.args['ms_n_mels'],\n",
    "            ms_sr = self.args['ms_sr'],\n",
    "            ms_fmax = self.args['ms_fmax'],\n",
    "            ms_channel = self.args['ms_channel'],\n",
    "            double_ended = self.args['double_ended'],\n",
    "            dim = self.args['dim'],\n",
    "            filename_column_ref = self.args['csv_ref'],\n",
    "        )\n",
    "\n",
    "\n",
    "        self.ds_val = NL.SpeechQualityDataset(\n",
    "            df_val,\n",
    "            df_con=dcon_val,\n",
    "            data_dir = self.args['data_dir'] + '/' + self.args['csv_db_val'][0],\n",
    "            filename_column = self.args['csv_deg'],\n",
    "            mos_column = self.args['csv_mos_val'],              \n",
    "            seg_length = self.args['ms_seg_length'],\n",
    "            max_length = self.args['ms_max_segments'],\n",
    "            to_memory = self.args['tr_ds_to_memory'],\n",
    "            to_memory_workers = self.args['tr_ds_to_memory_workers'],\n",
    "            seg_hop_length = self.args['ms_seg_hop_length'],\n",
    "            transform = None,\n",
    "            ms_n_fft = self.args['ms_n_fft'],\n",
    "            ms_hop_length = self.args['ms_hop_length'],\n",
    "            ms_win_length = self.args['ms_win_length'],\n",
    "            ms_n_mels = self.args['ms_n_mels'],\n",
    "            ms_sr = self.args['ms_sr'],\n",
    "            ms_fmax = self.args['ms_fmax'],\n",
    "            ms_channel = self.args['ms_channel'],\n",
    "            double_ended = self.args['double_ended'],\n",
    "            dim = self.args['dim'],\n",
    "            filename_column_ref = self.args['csv_ref'],                        \n",
    "            )\n",
    "\n",
    "        \n",
    "        self.ds_test = NL.SpeechQualityDataset(\n",
    "            df_test,\n",
    "            df_con=dcon_val,\n",
    "            data_dir = self.args['data_dir'] + '/' + self.args['csv_db_test'][0],\n",
    "            filename_column = self.args['csv_deg'],\n",
    "            mos_column = self.args['csv_mos_val'],              \n",
    "            seg_length = self.args['ms_seg_length'],\n",
    "            max_length = self.args['ms_max_segments'],\n",
    "            to_memory = self.args['tr_ds_to_memory'],\n",
    "            to_memory_workers = self.args['tr_ds_to_memory_workers'],\n",
    "            seg_hop_length = self.args['ms_seg_hop_length'],\n",
    "            transform = None,\n",
    "            ms_n_fft = self.args['ms_n_fft'],\n",
    "            ms_hop_length = self.args['ms_hop_length'],\n",
    "            ms_win_length = self.args['ms_win_length'],\n",
    "            ms_n_mels = self.args['ms_n_mels'],\n",
    "            ms_sr = self.args['ms_sr'],\n",
    "            ms_fmax = self.args['ms_fmax'],\n",
    "            ms_channel = self.args['ms_channel'],\n",
    "            double_ended = self.args['double_ended'],\n",
    "            dim = self.args['dim'],\n",
    "            filename_column_ref = self.args['csv_ref'],                        \n",
    "            )\n",
    "        \n",
    "        self.runinfos['ds_train_len'] = len(self.ds_train)\n",
    "        self.runinfos['ds_val_len'] = len(self.ds_val)\n",
    "        self.runinfos['ds_test_len'] = len(self.ds_test)\n",
    "    \n",
    "    def _loadModel(self):    \n",
    "        '''\n",
    "        Loads the Pytorch models with given input arguments.\n",
    "        '''   \n",
    "        # if True overwrite input arguments from pretrained model\n",
    "        if self.args['pretrained_model']:\n",
    "            if os.path.isabs(self.args['pretrained_model']):\n",
    "                model_path = os.path.join(self.args['pretrained_model'])\n",
    "            else:\n",
    "                model_path = os.path.join(os.getcwd(), self.args['pretrained_model'])\n",
    "            checkpoint = torch.load(model_path, map_location=self.dev)\n",
    "            \n",
    "            # update checkpoint arguments with new arguments\n",
    "            checkpoint['args'].update(self.args)\n",
    "            self.args = checkpoint['args']\n",
    "            \n",
    "        if self.args['model']=='NISQA_DIM':\n",
    "            self.args['dim'] = True\n",
    "            self.args['csv_mos_train'] = None # column names hardcoded for dim models\n",
    "            self.args['csv_mos_val'] = None  \n",
    "        else:\n",
    "            self.args['dim'] = False\n",
    "            \n",
    "        if self.args['model']=='NISQA_DE':\n",
    "            self.args['double_ended'] = True\n",
    "        else:\n",
    "            self.args['double_ended'] = False     \n",
    "            self.args['csv_ref'] = None\n",
    "\n",
    "        # Load Model\n",
    "        self.model_args = {\n",
    "            \n",
    "            'ms_seg_length': self.args['ms_seg_length'],\n",
    "            'ms_n_mels': self.args['ms_n_mels'],\n",
    "            \n",
    "            'cnn_model': self.args['cnn_model'],\n",
    "            'cnn_c_out_1': self.args['cnn_c_out_1'],\n",
    "            'cnn_c_out_2': self.args['cnn_c_out_2'],\n",
    "            'cnn_c_out_3': self.args['cnn_c_out_3'],\n",
    "            'cnn_kernel_size': self.args['cnn_kernel_size'],\n",
    "            'cnn_dropout': self.args['cnn_dropout'],\n",
    "            'cnn_pool_1': self.args['cnn_pool_1'],\n",
    "            'cnn_pool_2': self.args['cnn_pool_2'],\n",
    "            'cnn_pool_3': self.args['cnn_pool_3'],\n",
    "            'cnn_fc_out_h': self.args['cnn_fc_out_h'],\n",
    "            \n",
    "            'td': self.args['td'],\n",
    "            'td_sa_d_model': self.args['td_sa_d_model'],\n",
    "            'td_sa_nhead': self.args['td_sa_nhead'],\n",
    "            'td_sa_pos_enc': self.args['td_sa_pos_enc'],\n",
    "            'td_sa_num_layers': self.args['td_sa_num_layers'],\n",
    "            'td_sa_h': self.args['td_sa_h'],\n",
    "            'td_sa_dropout': self.args['td_sa_dropout'],\n",
    "            'td_lstm_h': self.args['td_lstm_h'],\n",
    "            'td_lstm_num_layers': self.args['td_lstm_num_layers'],\n",
    "            'td_lstm_dropout': self.args['td_lstm_dropout'],\n",
    "            'td_lstm_bidirectional': self.args['td_lstm_bidirectional'],\n",
    "            \n",
    "            'td_2': self.args['td_2'],\n",
    "            'td_2_sa_d_model': self.args['td_2_sa_d_model'],\n",
    "            'td_2_sa_nhead': self.args['td_2_sa_nhead'],\n",
    "            'td_2_sa_pos_enc': self.args['td_2_sa_pos_enc'],\n",
    "            'td_2_sa_num_layers': self.args['td_2_sa_num_layers'],\n",
    "            'td_2_sa_h': self.args['td_2_sa_h'],\n",
    "            'td_2_sa_dropout': self.args['td_2_sa_dropout'],\n",
    "            'td_2_lstm_h': self.args['td_2_lstm_h'],\n",
    "            'td_2_lstm_num_layers': self.args['td_2_lstm_num_layers'],\n",
    "            'td_2_lstm_dropout': self.args['td_2_lstm_dropout'],\n",
    "            'td_2_lstm_bidirectional': self.args['td_2_lstm_bidirectional'],                \n",
    "            \n",
    "            'pool': self.args['pool'],\n",
    "            'pool_att_h': self.args['pool_att_h'],\n",
    "            'pool_att_dropout': self.args['pool_att_dropout'],\n",
    "            }\n",
    "            \n",
    "        if self.args['double_ended']:\n",
    "            self.model_args.update({\n",
    "                'de_align': self.args['de_align'],\n",
    "                'de_align_apply': self.args['de_align_apply'],\n",
    "                'de_fuse_dim': self.args['de_fuse_dim'],\n",
    "                'de_fuse': self.args['de_fuse'],        \n",
    "                })\n",
    "                      \n",
    "        print('Model architecture: ' + self.args['model'])\n",
    "        if self.args['model']=='NISQA':\n",
    "            self.model = NL.NISQA(**self.model_args)     \n",
    "        elif self.args['model']=='NISQA_DIM':\n",
    "            self.model = NL.NISQA_DIM(**self.model_args)     \n",
    "        elif self.args['model']=='NISQA_DE':\n",
    "            self.model = NL.NISQA_DE(**self.model_args)     \n",
    "        else:\n",
    "            raise NotImplementedError('Model not available')                        \n",
    "        \n",
    "        # Load weights if pretrained model is used ------------------------------------\n",
    "        if self.args['pretrained_model']:\n",
    "            missing_keys, unexpected_keys = self.model.load_state_dict(checkpoint['model_state_dict'], strict=True)\n",
    "            # print('Loaded pretrained model from ' + self.args['pretrained_model'])\n",
    "            if missing_keys:\n",
    "                # print('missing_keys:')\n",
    "                print(missing_keys)\n",
    "            if unexpected_keys:\n",
    "                # print('unexpected_keys:')\n",
    "                print(unexpected_keys)        \n",
    "            \n",
    "    def _getDevice(self):\n",
    "        '''\n",
    "        Train on GPU if available.\n",
    "        '''         \n",
    "        if torch.cuda.is_available():\n",
    "            self.dev = torch.device(\"cuda\")\n",
    "        else:\n",
    "            self.dev = torch.device(\"cpu\")\n",
    "    \n",
    "        if \"tr_device\" in self.args:\n",
    "            if self.args['tr_device']=='cpu':\n",
    "                self.dev = torch.device(\"cpu\")\n",
    "            elif self.args['tr_device']=='cuda':\n",
    "                self.dev = torch.device(\"cuda\")\n",
    "        print('Device: {}'.format(self.dev))\n",
    "        \n",
    "        if \"tr_parallel\" in self.args:\n",
    "            if (self.dev==torch.device(\"cpu\")) and self.args['tr_parallel']==True:\n",
    "                self.args['tr_parallel']==False \n",
    "                # print('Using CPU -> tr_parallel set to False')\n",
    "\n",
    "    def _saveResults(self, model, model_args, opt, epoch, loss, ep_runtime, r, db_results, best):\n",
    "        '''\n",
    "        Save model/results in dictionary and write results csv.\n",
    "        ''' \n",
    "        if (self.args['tr_checkpoint'] == 'best_only'):\n",
    "            filename = self.runname + '.tar'\n",
    "        else:\n",
    "            filename = self.runname + '_' + ('ep_{:03d}'.format(epoch+1)) + '.tar'\n",
    "        model_path = os.path.join(self.args['output_dir'], filename)\n",
    "        results_path = os.path.join(self.args['output_dir'], self.runname+'__results.csv')\n",
    "        Path(self.args['output_dir']).mkdir(parents=True, exist_ok=True)              \n",
    "        \n",
    "        results = {\n",
    "            'runname': self.runname,\n",
    "            'epoch': '{:05d}'.format(epoch+1),\n",
    "            'filename': filename,\n",
    "            'loss': loss,\n",
    "            'ep_runtime': '{:0.2f}'.format(ep_runtime),\n",
    "            **self.runinfos,\n",
    "            **r,\n",
    "            **self.args,\n",
    "            }\n",
    "        \n",
    "        for key in results: \n",
    "            results[key] = str(results[key])                        \n",
    "\n",
    "        if epoch==0:\n",
    "            self.results_hist = pd.DataFrame(results, index=[0])\n",
    "        else:\n",
    "            self.results_hist.loc[epoch] = results\n",
    "        self.results_hist.to_csv(results_path, index=False)\n",
    "\n",
    "\n",
    "        if (self.args['tr_checkpoint'] == 'every_epoch') or (self.args['tr_checkpoint'] == 'best_only' and best):\n",
    "      \n",
    "            if hasattr(model, 'module'):\n",
    "                state_dict = model.module.state_dict()\n",
    "                model_name = model.module.name\n",
    "            else:\n",
    "                state_dict = model.state_dict()\n",
    "                model_name = model.name\n",
    "    \n",
    "            torch_dict = {\n",
    "                'runname': self.runname,\n",
    "                'epoch': epoch+1,\n",
    "                'model_args': model_args,\n",
    "                'args': self.args,\n",
    "                'model_state_dict': state_dict,\n",
    "                'optimizer_state_dict': opt.state_dict(),\n",
    "                'db_results': db_results,\n",
    "                'results': results,\n",
    "                'model_name': model_name,\n",
    "                }\n",
    "            \n",
    "            torch.save(torch_dict, model_path)\n",
    "            \n",
    "            model_files = sorted(glob(os.path.join(self.args['output_dir'], self.runname + '_ep_*.tar')))\n",
    "            if len(model_files) > 5:\n",
    "                for old_file in model_files[:-5]:\n",
    "                    os.remove(old_file)\n",
    "            \n",
    "        elif (self.args['tr_checkpoint']!='every_epoch') and (self.args['tr_checkpoint']!='best_only'):\n",
    "            raise ValueError('selected tr_checkpoint option not available')\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "yaml_file_path = 'config.yaml'  \n",
    "with open(yaml_file_path, \"r\") as ymlfile:\n",
    "    args_yaml = yaml.load(ymlfile, Loader=yaml.FullLoader)\n",
    "\n",
    "args = args_yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshubham-kumar1\u001b[0m (\u001b[33mshubham-kumar1-shl\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/ec2-user/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ec2-user/SageMaker/Noise_modelling/wandb/run-20241212_071834-87ayt481</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/shubham-kumar1-shl/Noise_Quality_Modelling/runs/87ayt481' target=\"_blank\">NISQA_transformer</a></strong> to <a href='https://wandb.ai/shubham-kumar1-shl/Noise_Quality_Modelling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/shubham-kumar1-shl/Noise_Quality_Modelling' target=\"_blank\">https://wandb.ai/shubham-kumar1-shl/Noise_Quality_Modelling</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/shubham-kumar1-shl/Noise_Quality_Modelling/runs/87ayt481' target=\"_blank\">https://wandb.ai/shubham-kumar1-shl/Noise_Quality_Modelling/runs/87ayt481</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Model architecture: NISQA\n",
      "Training size: 11020, Validation size: 2700\n",
      "pretrained_model: /home/ec2-user/SageMaker/Noise_modelling/pre_trained_model/NISQA/nisqa_mos_only.tar\n",
      "name: NISQA\n",
      "tr_epochs: 30\n",
      "tr_early_stop: 20\n",
      "tr_bs: 40\n",
      "tr_bs_val: 40\n",
      "tr_lr: 0.001\n",
      "tr_lr_patience: 15\n",
      "tr_num_workers: 4\n",
      "tr_parallel: true\n",
      "tr_ds_to_memory: false\n",
      "tr_ds_to_memory_workers: 0\n",
      "tr_verbose: 2\n",
      "tr_device: null\n",
      "ms_sr: null\n",
      "ms_fmax: 20000\n",
      "ms_n_fft: 4096\n",
      "ms_hop_length: 0.01\n",
      "ms_win_length: 0.02\n",
      "ms_n_mels: 48\n",
      "ms_seg_length: 15\n",
      "ms_seg_hop_length: 4\n",
      "ms_max_segments: 1300\n",
      "cnn_model: adapt\n",
      "cnn_c_out_1: 16\n",
      "cnn_c_out_2: 32\n",
      "cnn_c_out_3: 64\n",
      "cnn_kernel_size: !!python/tuple [3, 3]\n",
      "cnn_dropout: 0.2\n",
      "cnn_fc_out_h: null\n",
      "cnn_pool_1: [24, 7]\n",
      "cnn_pool_2: [12, 5]\n",
      "cnn_pool_3: [6, 3]\n",
      "td: self_att\n",
      "td_sa_d_model: 64\n",
      "td_sa_nhead: 1\n",
      "td_sa_pool_size: null\n",
      "td_sa_pos_enc: false\n",
      "td_sa_num_layers: 2\n",
      "td_sa_h: 64\n",
      "td_sa_dropout: 0.1\n",
      "td_lstm_h: null\n",
      "td_lstm_num_layers: null\n",
      "td_lstm_dropout: null\n",
      "td_lstm_bidirectional: null\n",
      "td_2: skip\n",
      "td_2_sa_d_model: null\n",
      "td_2_sa_nhead: null\n",
      "td_2_sa_pool_size: null\n",
      "td_2_sa_pos_enc: null\n",
      "td_2_sa_num_layers: null\n",
      "td_2_sa_h: null\n",
      "td_2_sa_dropout: null\n",
      "td_2_lstm_h: null\n",
      "td_2_lstm_num_layers: null\n",
      "td_2_lstm_dropout: null\n",
      "td_2_lstm_bidirectional: null\n",
      "pool: att\n",
      "pool_output_size: 1\n",
      "pool_att_h: 128\n",
      "pool_att_dropout: 0\n",
      "pool_lstm_dropout: null\n",
      "pool_lstm_h: null\n",
      "pool_lstm_num_layers: null\n",
      "pool_lstm_bidirectional: null\n",
      "de_align: null\n",
      "de_align_apply: null\n",
      "de_align_dim: null\n",
      "de_fuse_dim: null\n",
      "de_fuse: null\n",
      "model: NISQA\n",
      "dim: false\n",
      "double_ended: false\n",
      "data_dir: /home/ec2-user/SageMaker/Noise_modelling/dataset/NISQA_corpus/audios\n",
      "output_dir: /home/ec2-user/SageMaker/Noise_modelling/Finetuned_models/models/NISQA_transformer\n",
      "wandb_key: 584e51608456fd25214b6b929ce02762bfcba3a4\n",
      "wandb_proj_name: Noise_Quality_Modelling\n",
      "wandb_run_name: NISQA_transformer\n",
      "csv_file: /home/ec2-user/SageMaker/Noise_modelling/dataset/NISQA_corpus/csvs/train.csv\n",
      "csv_file_val: /home/ec2-user/SageMaker/Noise_modelling/dataset/NISQA_corpus/csvs/val.csv\n",
      "csv_file_test: /home/ec2-user/SageMaker/Noise_modelling/dataset/NISQA_corpus/csvs/test.csv\n",
      "csv_con: null\n",
      "csv_deg: filepath\n",
      "csv_mos_train: mos\n",
      "csv_mos_val: mos\n",
      "csv_mos_test: mos\n",
      "csv_db_train: [train]\n",
      "csv_db_val: [val]\n",
      "csv_db_test: [test]\n",
      "tr_checkpoint: every_epoch\n",
      "ms_channel: null\n",
      "tr_bias_mapping: null\n",
      "tr_bias_min_r: null\n",
      "tr_bias_anchor_db: null\n",
      "mode: main\n",
      "csv_ref: null\n",
      "now: 2024-12-12 07:18:35.650630\n",
      "\n",
      "runname: NISQA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> start training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” 100%, 276/276, 09:10<00:00, loss=2.36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<---- Training ---->\n",
      "<---- Validation ---->\n"
     ]
    }
   ],
   "source": [
    "wandb.login(key=args['wandb_key'])\n",
    "wandb.init(project=args['wandb_proj_name'], config=args, name=args['wandb_run_name'])\n",
    "\n",
    "nisqa = nisqaModel(args)\n",
    "nisqa._train_mos()\n",
    "\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
